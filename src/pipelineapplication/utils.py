def get_abstracts_to_analyze():
    """
    This is only a simple function that helps to keep the abstract to analyze
    :return: list of dictionaries
    """
    abstracts = [{
        "id": "5910db3edb2481b0340cb4c4e310ae9e3cf704a9",
        "title": "Neuron-Miner: An Advanced Tool for Morphological Search and Retrieval in Neuroscientific "
                 "Image Databases",
        "abstract": "The steadily growing amounts of digital neuroscientific data demands for a reliable, systematic, "
                    "and computationally effective retrieval algorithm. In this paper, we present Neuron-Miner, "
                    "which is a tool for fast and accurate reference-based retrieval within neuron image databases. "
                    "The proposed algorithm is established upon hashing (search and retrieval) technique by "
                    "employing multiple unsupervised random trees, collectively called as Hashing Forests (HF). "
                    "The HF are trained to parse the neuromorphological space hierarchically and preserve the "
                    "inherent neuron neighborhoods while encoding with compact binary codewords. We further introduce "
                    "the inverse-coding formulation within HF to effectively mitigate pairwise neuron similarity "
                    "comparisons, thus allowing scalability to massive databases with little additional time "
                    "overhead. The proposed hashing tool has superior approximation of the true neuromorphological "
                    "neighborhood with better retrieval and ranking performance in comparison to existing "
                    "generalized hashing methods. This is exhaustively validated by quantifying the results "
                    "over 31266 neuron reconstructions from Neuromorpho.org dataset curated from 147 different "
                    "archives. We envisage that finding and ranking similar neurons through reference-based "
                    "querying via Neuron Miner would assist neuroscientists in objectively understanding the "
                    "relationship between neuronal structure and function for applications in comparative anatomy "
                    "or diagnosis.",
        "outCitations": "ff9efce2c082d9e164065b8d6455e8c8a7233a26, 5042621f887cafde28ea4409aac9e33cb0f27d5b, "
                        "61b88be1ba215f18d371c97935e2a9fce46d7672, c9f50bc2b009dd1c957e60a5e8dd138e4c8f0ecd, "
                        "73d7218caa421995d63f83f694f4bcd83f3da44d, 5ae63da5d45cb38bfed8b737747264c645f25598, "
                        "9521d040f5d9c0b7f6683b08b31f8adfc8cb3121, deafc4e6e00765a26b934490d3e9f2aacd256767, "
                        "8121ce5d553a2a8b869629ce88610ad54428be04, 581c71da74bd3baa06693cc6d0751e7c60f81bb3, "
                        "90bc77b135ac7876290d3c251f0f1818584389b6, ed3c96f79ae477b28cf9cee2250fd120846416b2, "
                        "81b7e5635241f0fae8eac9f703f604a1a0073038, 2e74388f55f2cc704c4de410578887a53a9433b0, "
                        "58d07607dd35c39fefffd373d80f2a77ab18f5c7, c4ad1a762520cb799699e3bb209748a5881a554f, "
                        "9131b527b0e8269b3b1554aecd356bab060c9b86, 60352c78989537bb5e013f5b641e4605067857fa"
    }, {
        "id": "42d712639151b6d9948c78a211b6423473f94f25",
        "title": "Classical Capacities of Compound and Averaged Quantum Channels",
        "abstract": "We determine the capacity of compound classical-quantum channels. As a consequence, we obtain "
                    "the capacity formula for the averaged classical-quantum channels. The capacity result for "
                    "compound channels demonstrates, as in the classical setting, the existence of reliable universal "
                    "classical-quantum codes in scenarios where the only a priori information about the channel "
                    "used for the transmission of information is that it belongs to a given set of memoryless "
                    "classical-quantum channels. Our approach is based on a universal classical approximation of "
                    "the quantum relative entropy which in turn relies on a universal hypothesis testing result.",
        "outCitations": "482138b9af782e635f1e84c2fac4a3bce249e1ea, de7fd0c0234ca53afa0ab247e08ac0a87298b4ab, "
                        "e678a7146ce58db6246354ba2c92c048193e8c74, b36604c85940b0d4460edb98b497433e5c8119ac, "
                        "7b024b01dc792e6056ab4edcd3184a9d93ed627e, 7ffe3488e395d6ec98b1832e1ad0bbbc91a98a42, "
                        "42a0d8b7a95f5ecd67629f2317c56f177777882f, c8e624fbd17eea6c4ef88860ed9bb5c13d6243bb, "
                        "d676a895bafa8e04f4dd5e0529d7da9bba631429, 7a9af359627919c86ad4601e5eb6c5809d7725ad, "
                        "7d615699aa272629411330e931fc65d1acf58b66, c66db9b93d75c0ff52e7f84605b8389345307006, "
                        "f9fd91e7aaa744d6fbe00b435ebccc3f25a31a4b, 2db0c7e469dcbf18b950f2bdd554a85c6d32ba77, "
                        "3df694c49d651730ab6584a6fe9c3eb6519c6509"
    }, {
        "id": "a38483b3ad9a2590ea38562604b4360431f73e91",
        "title": "Association Analysis of Semi-structured Data for Discrimination Discovery in Business",
        "abstract": "Data mining techniques have taken a critical role in life in numerous domains such "
                    "as consumer analytics, finance, banking, medicine, biology, and astronomy... Recently, "
                    "data mining techniques have found their application also in discovering illegal "
                    "discriminatory treatment on the bases of sensitive attributes such as race, color, "
                    "religion, nationality, gender, age... In this paper, we propose a framework to solve "
                    "the discrimination matter in the context of semi-structured business data, and in particular "
                    "in the calculation of taxes for imported goods. This framework is able to discover possibly "
                    "discriminatory relations among data by finding discriminatory association rules with the "
                    "support of a common sense knowledge base and text mining techniques. The framework has applied "
                    "to the problem of HTS (US Harmonized Tariff Schedule) showing some satisfactory results.",
        "outCitations": "84b76c8fdde4919954fe36fdc0520e9d7dd17c86, 3e21a9b804553b6e2ab5beedf286c43b1975ecce, "
                        "c1fd505412ca40ffc74149f0a37043e77bd4b734, dbee4be7d2af340a0957da70627b561e29762181, "
                        "e671ec0b4d58329add3951c425f4ac2fc1ab371e, d2cad3a4139990496cd93fd6a5f93e68623456bb, "
                        "6ef12f4e6f120ba7fc8a83a610e3f362e0a133a7, c501acb1dbbab80212dc3ab005abf19560fe18f2, "
                        "94faf760b3b5070a56722436f49976e7ba0387ee, bb24f265ad1166f9b992561d165495c5c8b1d2ea, "
                        "1cd2e26d4abb3a303b22a96f35c874c0034878b3, a41109ab1338f918b5ba24a379686d5a30333449"
    }, {
        "id": "d644d4eb388885fe651257ad234b1cb9bb1dc0d4",
        "title": "Tensor Restricted Isometry Property Analysis For a Large Class of Random Measurement Ensembles",
        "abstract": "In previous work, theoretical analysis based on the tensor Restricted Isometry Property "
                    "(t-RIP) established the robust recovery guarantees of a low-tubal-rank tensor. The obtained "
                    "sufficient conditions depend strongly on the assumption that the linear measurement maps "
                    "satisfy the t-RIP. In this paper, by exploiting the probabilistic arguments, we prove that "
                    "such linear measurement maps exist under suitable conditions on the number of measurements in "
                    "terms of the tubal rank r and the size of third-order tensor n1, n2, n3. And the obtained "
                    "minimal possible number of linear measurements is nearly optimal compared with the degrees of "
                    "freedom of a tensor with tubal rank r. Specially, we consider a random sub-Gaussian distribution "
                    "that includes Gaussian, Bernoulli and all bounded distributions and construct a large class "
                    "of linear maps that satisfy a t-RIP with high probability. Moreover, the validity of the required "
                    "number of measurements is verified by numerical experiments.",
        "outCitations": "b5e853572b2f3134acafa76d5ae80b9f28c7dca8, 0c9bb579d8ad6ac987f7a16b66ddace671fc57c5, "
                        "6407ac1f051d30ca621ce16cf4ca67beb05930c6, 4f143cbc63e4c202db77566dac0f1f08c0774a45, "
                        "9fb8c76e6b17f3fdbd0c8f293ce8da4b79f4ffeb, ca96af5be9e713206b92e64f7824da1c2e38e4d4, "
                        "4f9f19e11baa16cb7ae27752864cb4231109b14c, 25ffa8c55f509241a577a6e6ec85792c66d1f41a, "
                        "ea1cf46db3f99aa538d8397e2d3cc9947213f0ad, 9336bfdcb40532ffd0d890854fee6fd3d98254ac, "
                        "7463c834bc397b6c4c2b1fd5e121b0f5007227cf, 6661789de63b3cebe2eafdd7e9e7a316ad1f0b8f, "
                        "81e8556180e4410b77c4cac9844f3547df97a345, 105858b27b052bd7f1e433f176fe8b4eb3f1ca84, "
                        "b1827bb4ee21b5e6b196b3f6995a9fa6928f716c, a07a7ea0cad9eb6e02fe8731c9f16c5115a16203, "
                        "e24c0387fa0ec3c32ebc97c050c94b8b01eeadd2, a57b6a19b1eef9228a034f61ba47022844cca042, "
                        "2ddc0494377c7cb162286cf6c5664ae901cda588, 5c2e30085a1cd03a36ca84c102eff54f9d923ad1, "
                        "fd37f013f36d9a0869a125499d7e9be1fcc3c1b3, 78e36cfa36220038ea3d79d3b0cc689238074e51, "
                        "2c2acfdbd61336f0b4d9974a7ff6ce963f6a73e5, 6179b2232c635008fed0f5ea0c8c5c82ccd1bdda, "
                        "f42f8d0b8e331255bcfe891e4ecebb5260b761c2, ae1483451dd70769ccbbf199d99cc553daa19852, "
                        "66f3f64b0a18b54642390dddbc2264093c63e3e3, 658339c73021674da17354eaaffc3cd326332117, "
                        "f6047e62635ebf241e3c9e6697d4fb39a098379f"
    }
    ]

    for elem in abstracts:
        elem["outCitations"] = elem["outCitations"].split(", ")

    return abstracts


def normalize_scores_on_cittopics(cittopic, p):
    """
    This function is used to normalize scores in a specific CitTopic
    :param cittopic: the CitTopic score list
    :param p: max score to assigned to a topic
    :return: the normalized CitTopic score list
    """
    max_value = p * len(cittopic) + 1

    return list(map(lambda x: x / max_value, cittopic))


def compute_missing_citations(cittopics, outcitations):
    """
    This function is used to compute the missing citations for a paper
    :param cittopics: the CitTopic
    :param outcitations: the list of records including outcitations
    :return: a list of missing citations
    """
    missing = []
    for c in cittopics:
        if c not in outcitations:
            missing.append(c)

    return missing


def compute_hit_citations(cittopics, outcitations):
    """
    This function is used to compute the missing citations for a paper
    :param cittopics: the CitTopic
    :param outcitations: the list of records including outcitations
    :return: a list of missing citations
    """
    hit = []
    for c in cittopics:
        if c in outcitations:
            hit.append(c)

    return hit


def get_valid_predictions(predictions, t):
    """
    This function is used to get all valid prediction taking into account a input threshold for probability
    :param t: threshold
    :param predictions: list prediction probability
    :return:
    """
    res = []
    for i in range(len(predictions)):
        if predictions[i] > t:
            res.append((i, predictions[i]))

    return res
